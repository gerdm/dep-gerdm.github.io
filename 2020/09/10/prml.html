<!DOCTYPE html><html lang="en" ><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="A journey through Pattern Recognition and Machine Learning" /><meta name="author" content="Gerardo" /><meta property="og:locale" content="en_US" /><meta name="description" content="On July 10, 2018 I committed myself to read and do all the exercises of the book Pattern Recognition and Machine Learning from Christopher Bishop. After seven hundred and ninety two days, I can finally say I accomplished my goal." /><meta property="og:description" content="On July 10, 2018 I committed myself to read and do all the exercises of the book Pattern Recognition and Machine Learning from Christopher Bishop. After seven hundred and ninety two days, I can finally say I accomplished my goal." /><link rel="canonical" href="http://0.0.0.0:3000/2020/09/10/prml" /><meta property="og:url" content="http://0.0.0.0:3000/2020/09/10/prml" /><meta property="og:site_name" content="Gerardo" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-09-10T00:00:00+01:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="A journey through Pattern Recognition and Machine Learning" /><meta name="twitter:site" content="@grrddm" /><meta name="twitter:creator" content="@Gerardo" /> <script type="application/ld+json"> {"description":"On July 10, 2018 I committed myself to read and do all the exercises of the book Pattern Recognition and Machine Learning from Christopher Bishop. After seven hundred and ninety two days, I can finally say I accomplished my goal.","headline":"A journey through Pattern Recognition and Machine Learning","dateModified":"2020-09-10T00:00:00+01:00","datePublished":"2020-09-10T00:00:00+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:3000/2020/09/10/prml"},"url":"http://0.0.0.0:3000/2020/09/10/prml","author":{"@type":"Person","name":"Gerardo"},"@type":"BlogPosting","@context":"https://schema.org"}</script><title> A journey through Pattern Recognition and Machine Learning - Gerardo</title><link rel="shortcut icon" href="/favicon.png"><link rel="alternate" type="application/atom+xml" title="Gerardo" href="/atom.xml"><link rel="alternate" type="application/json" title="Gerardo" href="http://0.0.0.0:3000/feed.json" /><link rel="sitemap" type="application/xml" title="sitemap" href="/sitemap.xml" /> <script src="https://kit.fontawesome.com/23a90fcaa1.js" crossorigin="anonymous"></script><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui, sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.5;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code,pre{background:#ecedee}code{padding:.1rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:0.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:0.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}</style></head><body><main role="main"><header role="banner"> <!--<h1 class="logo">Gerardo</h1>--><nav role="navigation"><ul><li><a href="/" >Writing</a></li><li><a href="/about" >About</a></li><li><a href="/search" >Search</a></li><li><a href="/atom.xml" >Rss</a></li></ul></nav></header><section class="post"><h2>A journey through Pattern Recognition and Machine Learning</h2><p>On July 10, 2018 I committed myself to read and do all the exercises of the book Pattern Recognition and Machine Learning from Christopher Bishop. After seven hundred and ninety two days, I can finally say I accomplished my goal.</p><p>One of the main reasons why I decided to study the book from cover to cover was to demystify machine learning (ML). Reading through the book taught me to question the underlying assumptions behind every model, to understand from a mathematical point of view why some models fail, and to not fret the mathematics behind ML. Most importantly, I understood why ML is hard, to be humbled by it and to not take models as recipes that we can use as we please.</p><p>Whilst studying the book, I had a small side project that consisted in clocking every time I opened the book using the <a href="https://toggl.com/">Toggl application</a>. The goal of this blog post, therefore, is not to discuss the intricate chapters of the book, but rather to tell a story with data on how I managed to finish the book, my experiences and what data can tell me about my own patterns.</p><h2 id="part1-temporal-analysis">Part1: Temporal Analysis</h2><h3 id="daily-hours">Daily Hours</h3><p>I started studying PRML on July 10, 2018 at 17:21pm. The first time I opened the book I did not know that I was going to read it from cover to cover. In fact, it was not until one month later, on august 27, 2018, the day of my birthday, that I decided to pursue a thorough study of the book. I do not recall much of that day, other than, according to my notes, I studied for 18 minutes. Interestingly though, my following two birthdays saw a rise the in the number of hours that I clocked:</p><table><thead><tr><th>Birthday year</th><th>clocked hours</th></tr></thead><tbody><tr><td>2018</td><td>0.3</td></tr><tr><td>2019</td><td>1.25</td></tr><tr><td>2020</td><td>2.43</td></tr></tbody></table><p>Around that time, I decided to study for two hours every single day until the day I finished the book. Considering the 792 days that took me to study the book from cover to cover, I should’ve gotten 1,584 hours worth of study, but instead, I got 1,542.72 hours. A close 97% of my goal.</p><p>The following graph shows the total number of clocked hours (top plot) and my deficit of hours (bottom plot), i.e., the difference between the number of hours that I should’ve studied v.s. the actual number of hours that I studied.</p><p><img src="https://imgur.com/NwbZcnR.png" alt="" /></p><p>An interesting observation from the graph above is to note the total number of days in which I did not clock a single hour of study is 48. Before starting doing this analysis I could’ve sworn that I had less than 5 days in which I did not study!</p><p>Another interesting observation from the previous graph is that I was on a time-deficit of almost 150 hours pre-covid19. But during the pandemic I managed to recover more than 100 hours worth of study, which led me to finish the book with a 43-hour deficit; or almost 21 days worth of study.</p><p>Without consideration of the days in which I did not clock my studies, I get an average study time of 2.17 hours per day. If I do consider them, I get an average of around 1.94 hours of study per day which, of course, is the 97% of 2.</p><p>The following graphs shows the distribution of hours of study per day without taking into account the 48 days in which I did not clock my studies. It shows that, on an average day, I would’ve studied between 1.4 and 3 hours.</p><p><img src="https://imgur.com/NZ17ZtR.png" alt="distribution-clocked-hours" /></p><h3 id="time-of-study">Time of study</h3><p>My decision to study two hours per day stemmed from the fact that I was working full-time on my startup. Even though I had more freedom to choose when I decided to start studying, I was constraint to my deadlines, meetings with clients, other models I was working on, etc. This, not only restricted how much could I study in one day, but also when did I start studying. In this section, I discuss my patterns in regards of my times of study.</p><p>The following histogram represents the distribution of times that I started clocking a study session. As we can see, it is centered at around 10 am, but it has a significant standard deviation of 4 hours. Meaning that roughly, on a normal day, I could’ve been studying anywhere from 6am to 2pm. Of course, these statistics do not truly represent what would happen on a normal day since the distribution seems to be right skewed and possibly multimodal.</p><p><img src="https://imgur.com/tnWVzvI.png" alt="time-of-start" /></p><p>In order to better understand my patterns of study we can consider the distribution of times that I started studying, grouped by weekday represented in the graph below. Clearly, Monday through Friday seem to be the days whose distributions look closest. Saturdays and Sundays however, diverge from the rest. Saturday, on the one hand, seems to have a mean that is closer to the early hours of the morning, while on the other hand, Sunday seems to be the weekday with higher probability of study in later hours of the day.</p><p><img src="https://imgur.com/mmQDQBF.png" alt="" /></p><p>An additional way to distill how much time I dedicated myself to study is to consider the following <em>heatmap</em> which represents the total number of hours that I studied, grouped by day of the week and the rounded hour in which I started studying.</p><p><img src="https://imgur.com/2SwWDxF.png" alt="" /></p><p>It came as a surprise to learn that my favorite day and hour of study was on Saturdays at 6am. In other timeframe did I get above 50 hours worth of study. Conversely, all workweek days seem pretty standard and not deviate much from the norm. On Sundays had the highest probability of studying after 9am. Finally, as with every dataset, there must be some outlier datapoints. In my case, it was the hours of study in very early in the morning, particularly on Thursdays.</p><h2 id="part-2-chapter-analysis">Part 2: Chapter Analysis</h2><p>As it is with any other topic in mathematics, not al subjects in a book have the same difficulty. One rough estimation on how hard each chapter was for me is to consider the amount of hours that I spent on that chapter.</p><pre><code>Chapter 1: Introduction                        128.755833
Chapter 2: Probability distributions           208.143611
Chapter 3: Linear Models for Regression        105.791389
Chapter 4: Linear Models for Classification    102.149167
Chapter 5: Neural Networks                     200.052120
Chapter 6: Kernel Methods                       61.676944
Chapter 7: Sparse Kernel Machines               79.763056
Chapter 8: Graphical Models                     96.968333
Chapter 9: Mixture Models and EM                79.607500
Chapter 10: Approximate Inference              226.593056
Chapter 11: Sampling Methods                    27.502500
Chapter 12: Continuous Latent Variables         91.390833
Chapter 13: Sequential Data                    104.260833
Chapter 14: Combining Models                    30.071667
Name: study-hours, dtype: float64
</code></pre><p>Before starting my analysis, I had the hypothesis that harder chapters must, of course, take longer to complete. What I did not consider, however, was the length of each chapter (which is easy to measure), the amount of hours that I dedicated myself to a particular exercise in the chapter (which I did not measure), and finally the <em>depth</em> of each chapter (which is hard to measure). Chapter 2, for example, was about topic I was already familiar with, namely, probability distributions. But despite this fact, it was the second chapter with most clocked hours. I did not feel that the chapter was particularly difficult, but the way in which the author talked about the subject made pay particularly attention to the details.</p><p>The following graph corrects for the number of pages in each chapter by dividing the total number of hours spent per chapter by the total number of pages in that chapter.</p><p><img src="https://imgur.com/5PrKNfY.png" alt="hours spent per chapter per page" /></p><p>Looking at the graph tells a slightly different story, but not the complete one. Chapter 14, for instance, was a high-pace chapter since it involved many concepts that were presented in earlier parts of the book, which made the reading easy to do and the exercises relatively easy to complete.</p><p>To finalize with this analysis, I can combined the previous two analyses to get to my final graph: the time spent on each chapter as a function of the date that I started studying it. The y-axis represents the total number of hours clocked per week, and the x-axis represents the end of each week.</p><p><img src="https://imgur.com/6DenEap.png" alt="" /></p><p>Looking at this graphs makes me quickly forget that the datapoints represent me. Between every two dashed lines in the graph there was a Gerardo experiencing something: a great weekend at the beach, a rough day at work, a day of worries or happiness. It sometimes easy to forget that as we work with data about people, there are stories that we are not taking account for. Latent variables that could better explain our patterns of behavior.</p><h2 id="conclusion">Conclusion</h2><p>The book Pattern Recognition and Machine Learning became my day-to-day life for more than two years. Looking back at my experiences with the book in the form of data is, to me, the only reasonable way to make an homage to such an inspiring book.</p><p>Furthermore, the analyses of my patterns in the form of hard data can help me overcome my next big goal. There are many things I would’ve done differently such as being more rigorous on how my data was extracted or write in words how I feeling on a particular day. But the key lesson that I learned from this experience is that <strong>consistency can take me anywhere</strong>.</p><h3 id="further-comments">Further comments</h3><ul><li>All the code used to make this post can be found in <a href="https://github.com/gerdm/misc/blob/master/2020-09/bishop-analysis.ipynb">this</a> notebook</li></ul><span class="meta"><time datetime="2020-09-10T00:00:00+01:00">September 10, 2020</time> &middot; <a href="/tag/data-analysis">data-analysis</a>, <a href="/tag/personal">personal</a></span></section></main></body></html>
